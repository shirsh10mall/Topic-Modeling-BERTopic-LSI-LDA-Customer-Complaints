{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nimport nltk\nfrom textblob import TextBlob\nimport matplotlib.pyplot as plt\nimport string","metadata":{"execution":{"iopub.status.busy":"2023-07-03T18:36:30.780638Z","iopub.execute_input":"2023-07-03T18:36:30.781088Z","iopub.status.idle":"2023-07-03T18:36:33.068249Z","shell.execute_reply.started":"2023-07-03T18:36:30.781054Z","shell.execute_reply":"2023-07-03T18:36:33.067002Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Import Data","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/consumer-complaint/complaints.csv\")\ndata = data[data[\"Consumer complaint narrative\"].isnull()==False]\ndata.reset_index(inplace=True, drop=True)\n# data[\"Consumer complaint narrative\"][np.random.randint(len(data),size=1)].values\nprint(\"Count of unique Issues: \", len(data[\"Issue\"].unique()))\n# data = data[0:3000]","metadata":{"execution":{"iopub.status.busy":"2023-07-03T18:36:33.070398Z","iopub.execute_input":"2023-07-03T18:36:33.070836Z","iopub.status.idle":"2023-07-03T18:37:29.985808Z","shell.execute_reply.started":"2023-07-03T18:36:33.070788Z","shell.execute_reply":"2023-07-03T18:37:29.984723Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Count of unique Issues:  160\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Cleaning","metadata":{}},{"cell_type":"code","source":"data[\"Consumer complaint narrative\"]\n\n# Lowercase\ndata[\"Consumer complaint narrative\"] = data[\"Consumer complaint narrative\"].progress_apply(lambda x: \" \".join(x.lower() for x in x.split()))\n\n# Removing Punctuation\ndata[\"Consumer complaint narrative\"] = data[\"Consumer complaint narrative\"].progress_apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n\n# # Removal of word having two or more \"x\" letters\ndata[\"Consumer complaint narrative\"] = data[\"Consumer complaint narrative\"].progress_apply(lambda x: \" \".join(x for x in x.split() if \"x\" not in x))\n\n# Removal of numbers and words having numbers\ndata[\"Consumer complaint narrative\"] = data[\"Consumer complaint narrative\"].progress_apply(lambda x: \" \".join(x for x in x.split() if not any(c.isdigit() for c in x)))\n\ndata[\"Consumer complaint narrative\"][100:1100].values","metadata":{"execution":{"iopub.status.busy":"2023-07-03T18:37:29.987777Z","iopub.execute_input":"2023-07-03T18:37:29.988247Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"792022e6b2a344c282eea7189c1e78d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88aa683a40c04672bdce631014dfa781"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2a86588c0e64e79b045484ae5578df2"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Data Visualization","metadata":{}},{"cell_type":"code","source":"# # Pie chart\n# labels = data[\"Timely response?\"].unique()\n# sizes = [len(data[data[\"Timely response?\"]==labels[0]]), len(data[data[\"Timely response?\"]==labels[1]])]\n# explode = (0.1, 0)  # explode 1st slice\n# # Plot\n# plt.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=False, startangle=140)\n# plt.axis('equal')\n# plt.title(\"Timely Response\")\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Histogram for Categorical Variable\n# data[\"Company response to consumer\"].value_counts().plot(kind='bar', title='Company response to consumer', figsize=(14, 6), rot=0, width=0.3 )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data[['Company response to consumer',\"Complaint ID\"]].groupby(by=\"Company response to consumer\").count().sort_values(\"Complaint ID\").plot(kind='bar', figsize=(15, 5), rot=0)\n# data[['State',\"Complaint ID\"]].groupby(by=\"State\").count().sort_values(\"Complaint ID\").plot(kind='bar', figsize=(25, 5), rot=0)\n\n\n# # Change into datatime format\n# data[\"Date received\"] = pd.to_datetime(data[\"Date received\"])\n# data_temp = data[[\"Complaint ID\",\"Date received\"]]\n# data_temp.sort_values(by=[\"Date received\"],inplace=True)\n# # Create year week column\n# data_temp[\"year_week\"] = data_temp[\"Date received\"].dt.strftime('%Y-%U')\n# data_temp = data_temp[[\"Complaint ID\",\"year_week\"]].groupby(by=\"year_week\").count().rename(columns={\"Complaint ID\":\"count\"})\n# data_temp.plot(figsize=(15,5), rot=0, title=\"Complaints per week\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data_temp = data[\"Consumer complaint narrative\"].apply(lambda x: TextBlob(x).sentiment.polarity)\n# plt.hist(data_temp, bins=50)\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Uni-gram using CountVectorizer\n# from sklearn.feature_extraction.text import CountVectorizer\n# cv = CountVectorizer(ngram_range=(1,1), stop_words='english')\n# cv.fit(data[\"Consumer complaint narrative\"])\n# sum_words = cv.transform(data[\"Consumer complaint narrative\"]).sum(axis=0)\n# words_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\n# words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n# # plot histogram for top 20 words\n# plt.figure(figsize=(15,5))\n# plt.bar([i[0] for i in words_freq[:20]], [i[1] for i in words_freq[:20]])\n# plt.xticks(rotation=30)\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Bi-gram\n# cv = CountVectorizer(ngram_range=(2,2), stop_words='english')\n# cv.fit(data[\"Consumer complaint narrative\"])\n# sum_words = cv.transform(data[\"Consumer complaint narrative\"]).sum(axis=0)\n# words_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\n# words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n# # plot histogram for top 20 words\n# plt.figure(figsize=(15,5))\n# plt.bar([i[0] for i in words_freq[:20]], [i[1] for i in words_freq[:20]])\n# plt.xticks(rotation=40)\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from wordcloud import WordCloud, STOPWORDS\n# stopwords = set(STOPWORDS)\n\n# wordcloud = WordCloud(width = 800, height = 800, stopwords=stopwords, max_words=100, max_font_size=40, random_state=10)\n\n# wordcloud=wordcloud.generate(\" \".join( data['Consumer complaint narrative'].values) )\n\n# fig = plt.figure(1, figsize=(12, 12))\n# plt.axis('off')\n# plt.imshow(wordcloud)\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data[[\"Issue\", \"Consumer complaint narrative\"]]\ndata = data[(data[\"Consumer complaint narrative\"]!=\"\")] \ndata.reset_index(inplace=True, drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save cleaned data\ndata.to_csv(\"complaints_cleaned.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport re\nimport gensim\nfrom gensim import corpora, models, similarities\nfrom gensim.parsing.preprocessing import STOPWORDS\nfrom nltk.corpus import stopwords","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load cleaned data\ndata = pd.read_csv(\"/kaggle/working/complaints_cleaned.csv\")\n# data.rename(columns={\"Consumer complaint narrative\":'text'},inplace=True)\ncolumn = \"Consumer complaint narrative\"\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing stopwords\n\nimport nltk\n# nltk.download('stopwords')\nimport gensim\nfrom gensim.parsing.preprocessing import STOPWORDS\nfrom nltk.corpus import stopwords\n \nstop_words = stopwords.words('english')\n\n# Remove stop words\ndata[column] = data[column].progress_apply(lambda x: \" \".join(x for x in x.split() if x not in stop_words))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Build the bigram and trigram models\n# bigram = gensim.models.Phrases(data[column].values, min_count=5, threshold=100) # higher threshold fewer phrases.\n# trigram = gensim.models.Phrases(bigram[column], threshold=100)  \n\n# # Faster way to get a sentence clubbed as a trigram/bigram\n# bigram_mod = gensim.models.phrases.Phraser(bigram)\n# trigram_mod = gensim.models.phrases.Phraser(trigram)\n\n# def make_bigrams(texts):\n#     return [bigram_mod[doc] for doc in texts]\n\n# def make_trigrams(texts):\n#     return [trigram_mod[bigram_mod[doc]] for doc in texts]\n\n# def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n#     texts_out = []\n#     for sent in texts:\n#         doc = nlp(\" \".join(sent)) \n#         texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n#     return texts_out","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lemmatization using spacy\nimport spacy\nnlp = spacy.load('en_core_web_sm',disable=['ner', 'parser']) # conda install -c conda-forge spacy-model-en_core_web_lg\ndef lemmatize_words(text):\n    doc = nlp(text)\n    return \" \".join([token.lemma_ for token in doc])\ndata[\"text_lemmatized\"] = data[column].progress_apply(lambda text: lemmatize_words(text))\n\n# Tokinization using spacy\ndef tokenize(text):\n    doc = nlp(text)\n    return [token.text for token in doc]\ndata[\"text_lemmatized\"] = data[\"text_lemmatized\"].progress_apply(lambda text: tokenize(text))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"text_lemmatized\"]","metadata":{"execution":{"iopub.status.busy":"2023-07-03T18:44:04.257981Z","iopub.execute_input":"2023-07-03T18:44:04.258427Z","iopub.status.idle":"2023-07-03T18:44:04.272894Z","shell.execute_reply.started":"2023-07-03T18:44:04.258397Z","shell.execute_reply":"2023-07-03T18:44:04.271649Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"0       [minimum, payment, fortiva, retail, credit, ca...\n1       [identity, steal, someone, create, fraudelunet...\n2       [I, m, send, complaint, inform, credit, bureau...\n3       [identity, theft, florida, date, birth, ss, fl...\n4       [file, numerous, complaint, credit, bureau, st...\n                              ...                        \n2994    [value, set, aside, margin, remove, portion, d...\n2995    [name, complaint, make, error, neither, make, ...\n2996    [accordance, fair, credit, reporting, act, lis...\n2997    [I, m, honestly, stump, regardless, many, time...\n2998    [fcra, violation, name, address, mine, fcra, v...\nName: text_lemmatized, Length: 2999, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"# Creating Document Term Matrix | Gensim","metadata":{}},{"cell_type":"code","source":"import gensim\nfrom gensim import corpora\n \n# Create Dictionary\nid2word_dictionary = corpora.Dictionary(data['text_lemmatized'].values)\n\n# Term Document Frequency\ncorpus = [id2word_dictionary.doc2bow(text) for text in data['text_lemmatized'].values]\n\n# View\nprint(corpus[0])","metadata":{"execution":{"iopub.status.busy":"2023-07-03T18:44:07.339612Z","iopub.execute_input":"2023-07-03T18:44:07.340518Z","iopub.status.idle":"2023-07-03T18:44:07.929906Z","shell.execute_reply.started":"2023-07-03T18:44:07.340475Z","shell.execute_reply":"2023-07-03T18:44:07.928764Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"[(0, 1), (1, 1), (2, 1), (3, 2), (4, 1), (5, 1), (6, 1), (7, 1), (8, 2), (9, 1), (10, 1), (11, 2), (12, 1), (13, 5), (14, 1), (15, 2), (16, 1), (17, 8), (18, 4), (19, 5), (20, 1), (21, 1), (22, 1), (23, 3), (24, 8), (25, 1), (26, 2), (27, 3), (28, 2), (29, 2), (30, 1), (31, 2), (32, 2), (33, 1), (34, 2), (35, 1)]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Implementation of LDA - Latent Dirichlet Allocation","metadata":{}},{"cell_type":"code","source":"# Build LDA model\nlda_model = gensim.models.LdaMulticore(corpus=corpus, id2word=id2word_dictionary, num_topics=10, random_state=10, \n                                        chunksize=100, passes=10, per_word_topics=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-03T18:44:08.163833Z","iopub.execute_input":"2023-07-03T18:44:08.164229Z","iopub.status.idle":"2023-07-03T18:44:23.239492Z","shell.execute_reply.started":"2023-07-03T18:44:08.164186Z","shell.execute_reply":"2023-07-03T18:44:23.237526Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from pprint import pprint\n\n# Print the Keyword in the 10 topics\npprint(lda_model.print_topics())\ndoc_lda = lda_model[corpus]","metadata":{"execution":{"iopub.status.busy":"2023-07-03T18:44:37.285288Z","iopub.execute_input":"2023-07-03T18:44:37.285711Z","iopub.status.idle":"2023-07-03T18:44:37.297089Z","shell.execute_reply.started":"2023-07-03T18:44:37.285676Z","shell.execute_reply":"2023-07-03T18:44:37.295807Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"[(0,\n  '0.039*\"identity\" + 0.037*\"theft\" + 0.037*\"balance\" + 0.036*\"information\" + '\n  '0.035*\"report\" + 0.022*\"consumer\" + 0.022*\"item\" + 0.020*\"block\" + '\n  '0.020*\"file\" + 0.018*\"require\"'),\n (1,\n  '0.070*\"fargo\" + 0.070*\"wells\" + 0.039*\"charge\" + 0.023*\"amount\" + 0.016*\"I\" '\n  '+ 0.013*\"transaction\" + 0.012*\"request\" + 0.012*\"product\" + 0.010*\"finance\" '\n  '+ 0.010*\"agreement\"'),\n (2,\n  '0.034*\"account\" + 0.023*\"bank\" + 0.021*\"call\" + 0.014*\"tell\" + '\n  '0.013*\"receive\" + 0.013*\"check\" + 0.012*\"card\" + 0.012*\"would\" + '\n  '0.010*\"say\" + 0.009*\"not\"'),\n (3,\n  '0.042*\"credit\" + 0.017*\"debt\" + 0.014*\"company\" + 0.010*\"collection\" + '\n  '0.010*\"report\" + 0.010*\"letter\" + 0.010*\"send\" + 0.009*\"one\" + 0.008*\"pay\" '\n  '+ 0.008*\"card\"'),\n (4,\n  '0.092*\"payment\" + 0.061*\"loan\" + 0.031*\"pay\" + 0.028*\"mortgage\" + '\n  '0.027*\"late\" + 0.023*\"month\" + 0.022*\"not\" + 0.017*\"make\" + 0.016*\"car\" + '\n  '0.015*\"do\"'),\n (5,\n  '0.029*\"report\" + 0.024*\"use\" + 0.023*\"consent\" + 0.021*\"make\" + '\n  '0.018*\"authorization\" + 0.017*\"credit\" + 0.017*\"consumer\" + 0.016*\"without\" '\n  '+ 0.015*\"personal\" + 0.015*\"account\"'),\n (6,\n  '0.042*\"consumer\" + 0.037*\"dispute\" + 0.035*\"information\" + 0.022*\"file\" + '\n  '0.022*\"agency\" + 0.016*\"provide\" + 0.014*\"item\" + 0.014*\"reporting\" + '\n  '0.013*\"section\" + 0.013*\"request\"'),\n (7,\n  '0.075*\"account\" + 0.068*\"report\" + 0.061*\"credit\" + 0.028*\"information\" + '\n  '0.022*\"remove\" + 0.020*\"inquiry\" + 0.020*\"date\" + 0.017*\"please\" + '\n  '0.017*\"number\" + 0.014*\"inaccurate\"'),\n (8,\n  '0.063*\"consumer\" + 0.060*\"usc\" + 0.058*\"section\" + 0.056*\"account\" + '\n  '0.049*\"reporting\" + 0.043*\"state\" + 0.039*\"information\" + 0.039*\"right\" + '\n  '0.035*\"agency\" + 0.025*\"furnish\"'),\n (9,\n  '0.051*\"consumer\" + 0.032*\"report\" + 0.032*\"information\" + 0.026*\"credit\" + '\n  '0.017*\"violation\" + 0.015*\"usc\" + 0.015*\"debt\" + 0.014*\"act\" + '\n  '0.013*\"creditor\" + 0.013*\"account\"')]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Evaluation | C_v Score","metadata":{}},{"cell_type":"code","source":"from gensim.models import CoherenceModel\n\n# Compute Coherence Score\ncoherence_model_lda = CoherenceModel(model=lda_model, texts=data[\"text_lemmatized\"].values, dictionary=id2word_dictionary, coherence='c_v')\ncoherence_lda = coherence_model_lda.get_coherence()\nprint('Coherence Score: ', coherence_lda)","metadata":{"execution":{"iopub.status.busy":"2023-07-03T18:44:42.219748Z","iopub.execute_input":"2023-07-03T18:44:42.220211Z","iopub.status.idle":"2023-07-03T18:44:48.209158Z","shell.execute_reply.started":"2023-07-03T18:44:42.220178Z","shell.execute_reply":"2023-07-03T18:44:48.207596Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Coherence Score:  0.5502356648213762\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"#  Function for TRaining LDA model and Computing Coherence Score\n\ndef Train_LDA_Compute_Coherence(corpus, dictionary, data_lemmatized, num_of_topics, alpha, beta, num_of_paases, coherence='c_v'):\n    \n    lda_model = gensim.models.LdaMulticore(corpus=corpus, id2word=dictionary, num_topics=num_of_topics, random_state=10,\n                                           chunksize=100, passes=num_of_paases, alpha=alpha, eta=beta)\n    \n    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=dictionary, coherence='c_v')\n    \n    return coherence_model_lda.get_coherence()\n\nscore = Train_LDA_Compute_Coherence(corpus=corpus, dictionary=id2word_dictionary, data_lemmatized=data[\"text_lemmatized\"].values, \n                                        num_of_topics=20, alpha=1, beta=1, num_of_paases=15)\nscore","metadata":{"execution":{"iopub.status.busy":"2023-07-03T18:44:48.211498Z","iopub.execute_input":"2023-07-03T18:44:48.211849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create Grid of Hyperparameters\n\n# Topics range\nmin_topics = 2\nmax_topics = 5\nstep_size = 1\ntopics_range = [5,25,50,100,150] # range(min_topics, max_topics, step_size)\n\n# Alpha parameter\nalpha_options = list(np.arange(0.01, 1, 0.475))\nalpha_options.append('symmetric')\nalpha_options.append('asymmetric')\n\n# Beta parameter\nbeta_options = list(np.arange(0.01, 1, 0.475))\nbeta_options.append('symmetric')\n\ntuning_results = pd.DataFrame(columns=['Number of Topics', 'Alpha', 'Beta'])\n\n# Create Array of possible combination of above parameters\nhyperparameters = np.array( np.meshgrid(alpha_options, beta_options, topics_range)).T.reshape(-1, 3)\ntuning_results['Alpha']= hyperparameters[:,0]\ntuning_results['Beta']= hyperparameters[:,1]\ntuning_results['Number of Topics']= hyperparameters[:,2]\ntuning_results","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tuning Process\n\nstages_of_passes = [2,5,10]\nnum_of_tops_hyperparameter = [5,3]\nnum_of_tops_hyperparameter.append( num_of_tops_hyperparameter[-1] )\ntuning_df = tuning_results.copy()\n\nfor stage in range(0,len(stages_of_passes)):\n    print(  )\n    scores = []\n    for i in tqdm(range(0,tuning_results.shape[0])):\n        hyperparameter = tuning_results.iloc[i]\n\n        try:\n            Alpha = float(hyperparameter['Alpha'])\n        except:\n            Alpha = hyperparameter['Alpha']\n\n        try:\n            Beta = float(hyperparameter['Beta'])\n        except:\n            Beta = hyperparameter['Beta']\n        \n        try:\n            Number_of_Topics = int(hyperparameter['Number of Topics'])\n        except:\n            Number_of_Topics = hyperparameter['Number of Topics']\n\n        \n        score = Train_LDA_Compute_Coherence(corpus=corpus, dictionary=id2word_dictionary, data_lemmatized=data[\"text_lemmatized\"].values, \n                                            num_of_topics=Number_of_Topics, alpha=Alpha, beta=Beta, num_of_paases=stages_of_passes[stage])\n        scores.append(score)\n\n    tuning_df[\"coherence score stage \" +  str(stage)] = score\n    tuning_df.sort_values(by=\"coherence score stage \" + str(stage),ascending=False)\n\n    tuning_df = tuning_df.head(num_of_tops_hyperparameter[stage])\n\ntuning_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Best Model\nbest_hyperparameters = tuning_df.iloc[0].to_dict()\nprint(\"Best Hyperparameters: \\n\", best_hyperparameters)\n\ntry:\n    best_hyperparameters['Alpha'] = float(best_hyperparameters['Alpha'])\nexcept:\n    pass\n\ntry:\n    best_hyperparameters['Beta'] = float(best_hyperparameters['Beta'])\nexcept:\n    pass\n\nbest_hyperparameters['Number of Topics'] = int( best_hyperparameters['Number of Topics'] )\n\n# Train Best Model\nlda_best_model = gensim.models.LdaMulticore(corpus=corpus, id2word=id2word_dictionary, num_topics=int(best_hyperparameters['Number of Topics']), random_state=10,\n                                             chunksize=100, passes=stages_of_passes[-1], alpha=best_hyperparameters['Alpha'], eta=best_hyperparameters['Beta'])\n\n# Compute Coherence Score\ncoherence_model_lda = CoherenceModel(model=lda_best_model, texts=data[\"text_lemmatized\"].values, dictionary=id2word_dictionary, coherence='c_v')\ncoherence_lda = coherence_model_lda.get_coherence()\nprint('\\n \\n Coherence Score of Best Model:-    c_v score= ', coherence_lda, \"  |   u_mass score= \", lda_best_model.log_perplexity(corpus))\n\n# Save Best Model\nlda_best_model.save(\"lda_best_model\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List topics modelled by Best Model\npprint(lda_best_model.print_topics())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print Document and corresponding Topic\nfor i in range(0,10):\n    print(\"Document: \", data[column][i])\n    print(\"Topic: \", lda_best_model[corpus[i]])\n    print(\" \")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization","metadata":{}},{"cell_type":"code","source":"# Visualize the topics\nimport pyLDAvis\npyLDAvis.enable_notebook()\n\nvis_graph = pyLDAvis.gensim_models.prepare(lda_best_model, corpus, id2word_dictionary)\nvis_graph","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LSA - Latent Semantic Analysis","metadata":{}},{"cell_type":"code","source":"from  import LsiModel\n\nlsi_model = LsiModel(corpus=corpus, num_topics=200, id2word=id2word_dictionary, chunksize=100, distributed=False, random_seed=10, onepass=True, power_iters=2)\ncoherence_model_lsi = CoherenceModel(model=lsi_model, texts=data['text_lemmatized'].values, dictionary=id2word_dictionary, coherence='c_v')\ncoherence_model_lsi.get_coherence()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function for Training LDA model and Computing Coherence Score\n\ndef Train_LSI_Compute_Coherence(corpus, dictionary, data_lemmatized, num_of_topics, coherence='c_v'):\n    \n    lsi_model = gensim.models.lsimodel.LsiModel(corpus=corpus, id2word=dictionary, num_topics=num_of_topics,\n                                                chunksize=100, distributed=False, random_seed=10, onepass=True, power_iters=2)\n    \n    coherence_model_lsi = CoherenceModel(model=lsi_model, texts=data_lemmatized, dictionary=dictionary, coherence='c_v')\n    \n    return coherence_model_lsi.get_coherence()\n\nscore = Train_LSI_Compute_Coherence(corpus=corpus, dictionary=id2word_dictionary, data_lemmatized=data[\"text_lemmatized\"].values, num_of_topics=20)\nscore","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finding Optimal Number of Topics\n\n# Topics range\nmin_topics = 2\nmax_topics = 5\nstep_size = 1\ntopics_range = [5,25,50,100,150]# range(min_topics, max_topics, step_size)\n\nscores = []\nfor i in tqdm(range(0,len(topics_range))):\n    score = Train_LSI_Compute_Coherence(corpus=corpus, dictionary=id2word_dictionary, data_lemmatized=data[\"text_lemmatized\"].values, num_of_topics=topics_range[i])\n    scores.append(score)\n\n# Plotting\nplt.figure(figsize=(10,5))\nplt.plot(topics_range)\nplt.xlabel(\"Number of Topics\")\nplt.ylabel(\"Coherence Score\")\nplt.title(\"Coherence Scores for LSI Model\")\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Final LSI Model\noptimal_number_of_topics = topics_range[np.argmax(scores)]\nbest_lsi_model = gensim.models.lsimodel.LsiModel(corpus=corpus, id2word=id2word_dictionary, num_topics=optimal_number_of_topics, chunksize=100, distributed=False, random_seed=10, onepass=True, power_iters=2)\nprint( \" Optimal Number of Topics: \", optimal_number_of_topics )\n# Compute Coherence Score\ncoherence_model_lsi = CoherenceModel(model=best_lsi_model, texts=data[\"text_lemmatized\"].values, dictionary=id2word_dictionary, coherence='c_v')\ncoherence_lsi = coherence_model_lsi.get_coherence()\nprint('\\n Coherence Score of Best Model:-    c_v score= ', coherence_lsi )\n\n# save best model\nbest_lsi_model.save(\"best_lsi_model\")                   ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List topics modelled by Best Model\npprint(best_lsi_model.print_topics())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}